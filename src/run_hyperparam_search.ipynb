{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adee767-0fe0-40c8-af36-5cea1a42bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# adding tools directory to path, so we can access the utils easily\n",
    "import sys\n",
    "root_path = os.path.join('.', 'tools')\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import file_tools\n",
    "_EXP_DIR = os.path.join('.', 'experiments')\n",
    "_DATASET_DIR = os.path.join(_EXP_DIR, 'datasets')\n",
    "\n",
    "_RESULTS_DIR = os.path.join(_EXP_DIR, 'results')\n",
    "file_tools.ensure_dir(_RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd4bd5-9440-4131-9d57-b767eae74455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_tools\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = dataset_tools.eeg_raw\n",
    "y = [distance.euclidean(row1, row2) for row1, row2 in zip(dataset_tools.observed_faces, dataset_tools.target_faces)]\n",
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(np.array(y).reshape(-1, 1)).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f583a6-589a-4f42-860a-8b21230daccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "estimator = Pipeline([\n",
    "    ('scaler_x', StandardScaler()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svr__C': [0.01, 0.1],\n",
    "    'svr__gamma': ['scale', 'auto'],\n",
    "    'svr__kernel': ['linear', 'rbf']\n",
    "}\n",
    "# best svr\n",
    "# {'svr__C': 0.01, 'svr__gamma': 'scale', 'svr__kernel': 'linear'}\n",
    "\n",
    "\n",
    "# estimator = Pipeline([\n",
    "#     ('scaler_x', StandardScaler()),\n",
    "#     ('mlp', MLPRegressor(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'mlp__hidden_layer_sizes': [2*(100,)],\n",
    "#     'mlp__activation': ['identity', 'relu'],\n",
    "#     'mlp__alpha': [0.1],\n",
    "#     'mlp__learning_rate': ['adaptive']\n",
    "# }\n",
    "\n",
    "# best mlp\n",
    "# {'mlp__activation': 'identity',\n",
    "#  'mlp__alpha': 0.1,\n",
    "#  'mlp__hidden_layer_sizes': (100, 100),\n",
    "#  'mlp__learning_rate': 'adaptive'}\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 0.1\n",
    "ss = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator, \n",
    "                            param_grid,\n",
    "                            cv=ss,    \n",
    "                            scoring=rmse_scorer,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=2)\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631223f8-3d9b-40e5-9326-279428ef82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert cv_results_ to a DataFrame\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('grid_search_results.csv', index=False)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the entire GridSearchCV object\n",
    "with open('grid_search_results.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search, f)\n",
    "\n",
    "# To load:\n",
    "# with open('grid_search_results.pkl', 'rb') as f:\n",
    "#     loaded_grid_search = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181d496-fb96-4b91-9e41-bf17f1506e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "plt.plot(results['mean_test_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56094d05-e0f2-47fe-b343-7e8eb6c0c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ec999-eb70-4f30-bb66-70b541ab706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X)\n",
    "plt.scatter(y, y_pred)\n",
    "plt.plot([-2, 2], [-2, 2], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a2345-4ab6-4757-9655-8a30754560ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips2025scbci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
