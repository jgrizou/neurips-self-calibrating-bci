# neurips-self-calibrating-bci
Code, data, and website associated the NeurIPS 2025 paper: 

Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels

```bibtex
@article{grizou2025self,
  title={Self-Calibrating BCIs: Ranking and Recovery of Mental Targets Without Labels},
  author={Grizou, Jonathan and de la Torre-Ortiz, Carlos and Ruotsalo, Tuukka},
  journal={Advances in Neural Information Processing Systems},
  volume={},
  pages={},
  year={2025}
}
```


## Large Files

We chose to upload most of the files directly to this repository. But some files are too large to be uploaded to GitHub, so we use Hugging Face Hub to host them. Large data files (GAN checkpoints, analysis results, some plots) can be automatically downloaded by running the following script:

```bash
python scripts/download_data.py
```

This will download:
- GAN checkpoint: `checkpoints/pggan_celebahq1024.pth` (264MB)
- Analysis results: `src/analysis/final_dfs/*.parquet` (up to 124MB each)
- Plot files: `src/analysis/plots/faces/*.eps`, `*.png`, `*.svg`

**Note**: The GAN model checkpoint is stored in the `checkpoints/` directory to avoid re-downloading from the OneDrive url in case the original endpoint stops functioning in the future. In case you run into this issue, run the setup script to copy it to all required locations:

```bash
./scripts/setup_checkpoints.sh
```

**Note:** If you encounter issues downloading files, please contact jonathan.grizou@grizai.com to obtain the data files directly.

## Data

All experimental data are stored in `src/data/all_data_sorted.npz`, containing:
- `target_faces`: Target face representations (9234 samples, 512 dimensions)
- `observed_faces`: Observed face representations (9234 samples, 512 dimensions)
- `eeg_raw`: Windowed EEG signals (9234 samples, 203 features from 29 channels Ã— 7 time windows)
- `eeg_net`: EEG features from neural network (9234 samples, 176 features)

## Getting Started

### 1. Create and activate a conda environment

```bash
conda create -n sc-bci python=3.8
conda activate sc-bci
```

### 2. Install dependencies

Install conda packages:
```bash
conda install --file conda_requirements.txt
```

Install pip packages:
```bash
pip install -r pip_requirements.txt
```

### 3. Setup experiments

```bash
python src/setup_experiments.py
```

This script uses the raw data to generate the experiment datasets, creating train/test/target splits in the `experiments/datasets/` directory.

### 4. Run experiments

```bash
python src/run_experiments.py
```

Results are stored in `experiments/results/`. You can parameterize the experiments by modifying these variables in `run_experiments.py`:

```python
method_names = ['DummyScoring_Mean', 'Shuffle_LinearRegression', 'LinearRegression']
training_sizes = [9234]
eeg_names = ['EEG_Raw']  # Options: ['EEG_Raw', 'EEG_Net']
```

### 5. Run optimization

```bash
python src/run_optimisation.py
```

This runs CMA-ES optimization using Optuna to find the best face parameters. Results are stored in `experiments/optim/`. Key parameters to configure in `run_optimisation.py`:

```python
method_names = ['LinearRegression', 'Shuffle_LinearRegression', 'DummyScoring_Mean']
eeg_names = ['EEG_Raw']  # Options: ['EEG_Raw', 'EEG_Net']
n_components_face = [10]  # PCA dimensionality for face space
_N_TRIALS = 1000  # Number of optimization trials
_BOUNDS = 15  # Search space bounds
```

## Additional Experiments

**Ablation studies** (`run_ablation.py`, `run_optimisation_ablation.py`): Test the impact of removing training data within varying distances from the target. Results stored in `experiments/results_ablation/` and `experiments/optim_ablation/`.

**Dimensionality studies** (`run_dimensionality_eeg.py`, `run_dimensionality_face.py`): Test different PCA dimensionalities for EEG and face representations. Results stored in `experiments/results_dimensionality_eeg/` and `experiments/results_dimensionality_face/`.

## Human Experiment Application

The `src/user_experiments/` folder contains a web application for running human participant tests:

```bash
cd src/user_experiments
python app.py
```

Participant results are saved to the `results/` folder. Face stimuli can be generated using `generate_experiment_faces.ipynb`, but precomputed pairs of faces for the experiments are provided in the `static/` folder for convenience.

## Analysis

The `src/analysis/` folder contains scripts and results for analyzing experimental data:

### Folder Structure

- **`csv_files/`**: Data from user studies from previous work
- **`final_dfs/`**: Processed results in parquet format, generated by running `gather_results.py` and `compile_final_df.ipynb`. These files are provided directly in the repository, but keen researchers could reconstruct them by running their own experiments (saved in the `experiments/` folder) and processing the results with the analysis scripts.
- **`plots/`**: Generated plots and figures for the paper, created from the `final_dfs/` data. Plots are provided in the repository but can be regenerated using the notebooks provided in the plots subfolders.
